---
title: Project Review Template 
author: Rayleen Lewis
date: April 20, 2025
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
---

# Overview

Title of project: Exploring clinical and non-clinical(food) Listeria monocytogenes isolates

Name of project author(s): Alexis Gonzalez

Name of project reviewer: Rayleen Lewis


# Instructions

Write your comments and feedback below for each section/component of the project. The goal should be to help the author improve their project. Make comments as constructive and actionable as possible. You can provide both criticism and praise.

For each component, pick one summary statement by deleting the ones that do not apply and keeping only the one that you think most closely summarizes a given component. 

Make sure your final document compiles/renders into a readable, well-formatted html document.

Delete any sections/text of this template that are not part of your final review document. (Including these instructions.)


# Specific project content evaluation
Evaluate the different parts of the project by filling in the sections below.


## Background, Context and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments

Information on the burden and sources of Listeria outbreaks is provided, as is information on recent Listeria outbreaks. The information included is good, but the intro doesn't have any citations. These need to be added for the final project.

### Summary assessment (PICK ONE, DELETE THE OTHERS)]
* some contextualization and motivation



## Question description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?


### Feedback and Comments

The objective is somewhat clear. Adding definitions of "clinical" and "non-clinical" samples would be helpful. Are clinical from patients seeking medical treatment while non-clinical are directly from food/food processing equipment? The data seem appropriate for answering the question. There isn't a hypothesis, but this seems more of an exploratory aim, so I think that's fine.

### Summary assessment
* question/hypotheses somewhat explained


## Data description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

### Feedback and Comments

The overall purpose of the data source is described. It is unclear what variables/information are included in the data; only variables that are excluded were mentioned. References should be added for the data sources. This could be a reference to a website if data are available online or a methods paper describing the platforms.

### Summary assessment
* source and overall structure of data poorly explained


## Data wrangling and exploratory analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments

Not all characteristics were looked at during the exploratory data analysis, but I'm not sure if this was appropriate since a description of the characteristics wasn't included. For example, would it have been useful to look at cluster and see if the case counts per cluster made sense? Also, did you consider recategorizing location to be state level? Most of the locations are state, but some are city. I'm not sure if this would be of interest in your analysis. There is no supplementary material. Wrangling steps are described in the methods.

### Summary assessment
* some weaknesses in wrangling and exploratory component



## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

### Feedback and Comments

There's virtually no analysis in the manuscript. The manuscript includes 2 figures, which don't have descriptive titles or legends. Please explain what Yes/No response is in reference to for the first figure, and 0/1 for outcome and starting point for days counter in the second figure. For the analysis code itself, if the goal is to look at trends, I don't think it's appropriate to use day of the year, week, and month as separate predictors in your model. These are essentially providing the same information at different levels of detail. For example, weeks 1-4 will all have a month = 1.  

### Summary assessment
* wrong/inadequate analysis

## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments

See comments above about improving figures. No other analyses are included in the manuscript. Also, code to execute inclusion of the figures should be removed. The manuscript file also includes a leftover table from the template.

### Summary assessment
* results are poorly presented, hard to understand, poor quality


## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments

This section is missing entirely.

### Summary assessment
* major parts of discussion missing or wrong 


## Further comments

Because of the major gaps in the project, I'm wondering if updates on the project weren't pushed to GitHub. 

# Overall project content evaluation
Evaluate overall features of the project  by filling in the sections below.


## Structure
Is the project well structured? Are files in well labeled folders? Do files have reasonable names? Are all "junk" files not needed for analysis/reproduction removed? By just looking at files and folders, can you get an idea of how things fit together?

### Feedback and Comments

Most of the template files are still in the folders, so it is confusing to figure out which files were leftover from the template and which files were relevant for this project. The file names are all from the template, so they make sense. Files do appear in the expected folders (e.g., figures are in the figures folder).

### Summary assessment
* mostly clear, but some confusing parts (e.g. useless files, things in the wrong folders)


## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

All files include some level of comments, including some text explaining findings from figures. For some code blocks this is minimal. For example, some comments are very broad like "build model" and "run metrics." More details, like what type of model is being built or which metrics you're using to evaluate model performance, would be helpful. 

### Summary assessment
* decently documented with some gaps



## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention? Are you able to re-run the whole analysis without having to do manual interventions/edits?

### Feedback and Comments
All of the ReadMe files should be updated to describe this project and should include information on what code should be run in what order. Because a lot of files are left over from the template, it is unclear which files I should run to reproduce the project.

I did get some errors when running the code files that I think are for this project and not the template:
Statistical analysis code:
- Lines 60-66:  I couldn't reproduce this figure (error: object 'predicted_prob' not found)

Manuscript code:
- Line 79: This was added to the end of the line which prevented the document from rendering "...................;;;;;;;;;;;;;;;::::::::::::::::P"

### Summary assessment
* small parts not reproducible or required manual intervention 


## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

### Feedback and Comments

Most of the analysis is missing from the manuscript, the statistical code only ran a single model (random forest), and the discussion is not included. 

### Summary assessment
* weak level of thoroughness


## Further comments

It's very important to update the ReadMe files so someone new to the project knows what to expect in the folders and which files to run. Also, deleting template files that aren't part of the project would help a lot when this is reviewed for final grading.





